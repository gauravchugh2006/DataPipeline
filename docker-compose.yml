version: '3.8'

networks:
  default:
    name: datahub_network

# Define the custom Airflow settings that will be reused (the anchor must be defined first)
x-airflow-common: &airflow-common
  image: apache/airflow:2.3.4-python3.10
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__FERNET_KEY=ehE_UybKeIGETmag57Fy1MBeAIQRWDt7NS9zcl017Yg=
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${AIRFLOW_DB_USER:-airflow}:${AIRFLOW_DB_PASSWORD:?AIRFLOW_DB_PASSWORD not set}@postgres_airflow/airflow
    - AIRFLOW__CORE__LOAD_EXAMPLES=True
    - AIRFLOW__CORE__DAGS_ARE_PAUSED_CREATION=False
    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    - AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=True
    - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
    - AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8082
    - AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1
    - _PIP_ADDITIONAL_REQUIREMENTS=pandas==2.0.3 psycopg2-binary==2.9.5 boto3==1.26.76 dbt-core==1.4.5 dbt-postgres==1.4.5 minio==7.1.13
  volumes:
    - ./dags:/opt/airflow/dags:rw
    - ./airflow-data/logs:/opt/airflow/logs:rw
    - ./airflow-data/plugins:/opt/airflow/plugins:rw
    - ./airflow-data/airflow.cfg:/opt/airflow/airflow.cfg:rw
    - ./dbt_profiles:/opt/airflow/.dbt:rw
    - ./docker-compose.yml:/opt/airflow/docker/docker-compose.yml:ro
    - ./security-reports:/opt/airflow/security-reports:rw

services:

  ### üöÄ PostgreSQL for Airflow & Metadata Storage ###
  postgres_airflow:
    image: postgres:15
    container_name: postgres_airflow
    environment:
      POSTGRES_USER: ${AIRFLOW_DB_USER:-airflow}
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD:?AIRFLOW_DB_PASSWORD not set}
      POSTGRES_DB: airflow
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: always
    ports:
      - "5439:5432"
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data

  ### üöÄ Redis for Airflow Caching ###
  redis:
    image: redis:7.2-bookworm
    container_name: redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always

  ### üöÄ Apache Airflow ###
  airflow:
    image: apache/airflow:2.3.4-python3.10
    container_name: airflow
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_DB_USER:-airflow}:${AIRFLOW_DB_PASSWORD:?AIRFLOW_DB_PASSWORD not set}@postgres_airflow/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "true"
    depends_on:
      - postgres_airflow
    ports:
      - "8082:8082"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./airflow-data/airflow.cfg:/opt/airflow/airflow.cfg
      - ./dbt_profiles:/opt/airflow/.dbt
    command: webserver

  # ‚úÖ Airflow Init Service (runs once after everything is set up)
  airflow-init:
    image: apache/airflow:2.3.4-python3.10       # Use the same version as your primary Airflow service
    container_name: airflow_init
    restart: "no"                   # Do not restart‚Äîrun once and exit
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_DB_USER:-airflow}:${AIRFLOW_DB_PASSWORD:?AIRFLOW_DB_PASSWORD not set}@postgres_airflow/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "true"
    command: >
      bash -cx '
      echo "Waiting for Postgres to be ready...";
      until pg_isready -h postgres_airflow -p 5432 -U airflow; do
        echo "Postgres not ready yet, sleeping 5 seconds...";
        sleep 5;
      done;
      echo "Postgres is ready. Initializing Airflow DB...";
      airflow db init;
      echo "Airflow DB initialized. Creating admin user...";
      airflow users create --username airflow --firstname Air --lastname Flow --role Admin --email airflow@example.com -p airflow || true;
      echo "Airflow initialization tasks complete."'
    depends_on:
      postgres_airflow:
        condition: service_healthy
 
  ### üê≥ Airflow Scheduler service ###
  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    command: airflow scheduler
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres_airflow:
        condition: service_healthy
      redis:
        condition: service_healthy

  ### üõ†Ô∏è MinIO (S3-compatible Object Storage) ###
  minio:
    image: minio/minio
    container_name: minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000" # ‚Üí Connects to container port 9000 (API Server) / Used for S3-compatible object storage operations
      - "9001:9001"  # ‚Üí Connects to container port 9001 (Console) / Admin Dashboard
    volumes:
      - minio_data:/data

  ### üóÉÔ∏è PostgreSQL for Metadata (DBT, DataHub) ###
  postgres_dw:
    image: postgres:15
    container_name: postgres_dw
    environment:
      POSTGRES_USER: ${POSTGRES_DWH_USER:-dwh_user}
      POSTGRES_PASSWORD: ${POSTGRES_DWH_PASSWORD:?POSTGRES_DWH_PASSWORD not set}
      POSTGRES_DB: datamart
    healthcheck:
     test: ["CMD-SHELL", "pg_isready -U dwh_user -d datamart -h localhost || exit 1"]
     interval: 10s
     timeout: 5s
     retries: 5
     start_period: 30s
    restart: always
    ports:
      - "5432:5432"
    volumes:
      - postgres_dw_data:/var/lib/postgresql/data

  ### üß™ SonarQube for Code Quality Analysis (SAST) ###
  sonarqube:
    image: sonarqube:9.9-community
    container_name: sonarqube
    restart: always
    depends_on:
      - postgres_sonar
    environment:
      SONAR_JDBC_URL: jdbc:postgresql://postgres_sonar:5432/sonar
      SONAR_JDBC_USERNAME: sonar    # ‚Üê This is the DATABASE user
      SONAR_JDBC_PASSWORD: ${SONAR_DB_PASSWORD:?SONAR_DB_PASSWORD not set}    # ‚Üê This is the DATABASE password
      SONARQUBE_JDBC_USERNAME: ${SONAR_DB_USER:-sonar}
      SONARQUBE_JDBC_PASSWORD: ${SONAR_DB_PASSWORD:?SONAR_DB_PASSWORD not set}
    # Add this to set a custom admin password:
    # Note: This only works on first initialization, before password is set
    # SONARQUBE_ADMIN_PASSWORD: your_secure_password (default is user 'admin' and password 'admin')
    ports:
      - "9003:9000"  # ‚úÖ Host port 9003 ‚Üí Container port 9000 (SonarQube Web Interface)

  ### üêò PostgreSQL for SonarQube ###
  postgres_sonar:
    image: postgres:15
    container_name: sonar-postgres-db
    environment:
      POSTGRES_USER: ${SONAR_DB_USER:-sonar}
      POSTGRES_PASSWORD: ${SONAR_DB_PASSWORD:?SONAR_DB_PASSWORD not set}
      POSTGRES_DB: ${SONAR_DB_NAME:-sonar}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sonar -d sonar -h localhost || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: always
    ports:
      - "5433:5432"
    volumes:
      - sonar_postgres_data:/var/lib/postgresql/data
  
  ### üõ°Ô∏è OWASP ZAP Baseline Scan ###
  zap-baseline:
    image: ghcr.io/zaproxy/zaproxy:weekly
    depends_on:
      - airflow
    working_dir: /zap/wrk
    restart: "no"
    environment:
      ZAP_BASELINE_TARGET: ${ZAP_BASELINE_TARGET:-http://airflow:8082}
      ZAP_REPORTS_DIR: /zap/wrk/security-reports
      ZAP_CONFIG_FILE: /zap/wrk/zap-baseline.conf
    entrypoint: >
      sh -c "mkdir -p ${ZAP_REPORTS_DIR} &&
      zap-baseline.py
      -t ${ZAP_BASELINE_TARGET}
      -r ${ZAP_REPORTS_DIR}/zap-baseline.html
      -J ${ZAP_REPORTS_DIR}/zap-report.json
      -x ${ZAP_REPORTS_DIR}/zap-report.xml
      -c ${ZAP_CONFIG_FILE}
      -m 5"
    volumes:
      - ./security-reports:/zap/wrk/security-reports
      - ./zap-baseline.conf:/zap/wrk/zap-baseline.conf
##    profiles: ["zap"]

  ### üõ°Ô∏è OWASP ZAP Full Scan (DAST) ###
  zap-full:
    image: ghcr.io/zaproxy/zaproxy:weekly
    depends_on:
      - airflow
    working_dir: /zap/wrk
    command: >
      zap-full-scan.py
      -t http://airflow:8082
      -r zap-full.html
      -J zap-full.json
      -x zap-full.xml
      -m 10
    volumes:
      - ./security-reports:/zap/wrk
#    profiles: ["zap"]

  ### üß† Neo4j Graph Database ###
  neo4j:
    image: neo4j:4.4.9-community
    container_name: neo4j
    environment:
      - NEO4J_AUTH=neo4j/datahub
      - NEO4J_dbms_default__database=graph.db
      - NEO4J_dbms_allow__upgrade=true
      - NEO4JLABS_PLUGINS=["apoc"]
    healthcheck:
      interval: 5s
      retries: 10
      start_period: 60s
      test: wget http://neo4j:7474
      timeout: 20s
    hostname: neo4j
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data

  ### üîç Zookeeper (Kafka Dependency) ###
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    healthcheck:
      interval: 5s
      retries: 3
      start_period: 10s
      test: echo srvr | nc zookeeper 2181
      timeout: 5s
    hostname: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - zkdata:/var/lib/zookeeper/data
      - zklogs:/var/lib/zookeeper/log

  ### üî• Kafka (Broker for DataHub) ###
  broker:
    image: confluentinc/cp-kafka:7.4.0
    container_name: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_HEAP_OPTS=-Xms256m -Xmx256m
      - KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE=false
      - KAFKA_MESSAGE_MAX_BYTES=5242880
      - KAFKA_MAX_MESSAGE_BYTES=5242880
    healthcheck:
      interval: 1s
      retries: 5
      start_period: 60s
      test: nc -z broker $${DATAHUB_KAFKA_BROKER_PORT:-9092}
      timeout: 5s
    hostname: broker
    ports:
      - "9092:9092"
    volumes:
      - broker:/var/lib/kafka/data/

  ### üìú Schema Registry (Ensures Consistent Message Formats) ###
  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    container_name: schema-registry
    depends_on:
      - broker
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
    ports:
      - "8081:8081"

  ### üîç DataHub Core Components ###
  datahub-gms:
    image: acryldata/datahub-gms:head
    container_name: datahub-gms
    environment:
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      DATAHUB_SECRET: YouKnowNothing
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      EBEAN_DATASOURCE_USERNAME: dwh_user
      EBEAN_DATASOURCE_PASSWORD: ${POSTGRES_DWH_PASSWORD:?POSTGRES_DWH_PASSWORD not set}
      EBEAN_DATASOURCE_HOST: postgres_dw
      EBEAN_DATASOURCE_PORT: 5432
      EBEAN_DATASOURCE_URL: jdbc:postgresql://postgres_dw:5432/datamart
      EBEAN_DATASOURCE_DRIVER: org.postgresql.Driver
      NEO4J_HOST: neo4j:7687
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USERNAME: neo4j
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-datahub}
    ports:
      - "8080:8080"
    depends_on:
      - postgres_dw
      - broker

  datahub-actions:
    image: acryldata/datahub-actions:head
    container_name: datahub-actions
    environment:
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      DATAHUB_SECRET: YouKnowNothing
      KAFKA_BOOTSTRAP_SERVER: broker:29092
    depends_on:
      - datahub-gms

  datahub-frontend-react:
    image: acryldata/datahub-frontend-react:head
    container_name: datahub-frontend-react
    depends_on:
      - datahub-gms
    environment:
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      DATAHUB_SECRET: YouKnowNothing
    ports:
      - "9002:9002"

volumes:
  broker:
  postgres_dw_data:
  postgres_airflow_data:
  minio_data:
  neo4j_data:
  zkdata:
  zklogs:
  sonar_postgres_data:
