[0m15:43:03.187404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce687f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce46173d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce4616250>]}


============================== 15:43:03.207060 | f0b2c889-f0bd-4ab1-b06f-b53a65379707 ==============================
[0m15:43:03.207060 [info ] [MainThread]: Running with dbt=1.9.3
[0m15:43:03.211130 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': '/root/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:43:03.215857 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path /usr/app/dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m15:43:03.222594 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.21082681, "process_in_blocks": "0", "process_kernel_time": 0.329457, "process_mem_max_rss": "89136", "process_out_blocks": "56", "process_user_time": 3.074937}
[0m15:43:03.228622 [debug] [MainThread]: Command `dbt build` failed at 15:43:03.228222 after 0.22 seconds
[0m15:43:03.232519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce467a0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce4620cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ce4694f90>]}
[0m15:43:03.235430 [debug] [MainThread]: Flushing usage events
[0m15:43:03.727622 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:48:40.119844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c14d63b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c16f8ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c15255350>]}


============================== 15:48:40.126710 | 97956a3b-3b29-485a-9bc4-1ecbbd8d259d ==============================
[0m15:48:40.126710 [info ] [MainThread]: Running with dbt=1.9.3
[0m15:48:40.129810 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/root/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt build', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:48:40.133805 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path /usr/app/dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m15:48:40.140034 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.08782516, "process_in_blocks": "0", "process_kernel_time": 0.101249, "process_mem_max_rss": "88532", "process_out_blocks": "0", "process_user_time": 1.093493}
[0m15:48:40.143838 [debug] [MainThread]: Command `dbt build` failed at 15:48:40.143651 after 0.09 seconds
[0m15:48:40.147684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c14da9150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c14d40c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c14d94f10>]}
[0m15:48:40.148976 [debug] [MainThread]: Flushing usage events
[0m15:48:40.543797 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:49:57.719812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d694cd510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d694b3390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d69bbb350>]}


============================== 15:49:57.726955 | 5ddabc5b-af7b-4d38-995c-2f379213e4d4 ==============================
[0m15:49:57.726955 [info ] [MainThread]: Running with dbt=1.9.3
[0m15:49:57.730273 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/root/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:49:57.742139 [info ] [MainThread]: Error importing adapter: No module named 'dbt.adapters.postgres'
[0m15:49:57.743412 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "data_pipeline", target "dev" invalid: Runtime Error
    Could not find adapter type postgres!
[0m15:49:57.745787 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 0.10207198, "process_in_blocks": "0", "process_kernel_time": 0.099116, "process_mem_max_rss": "88088", "process_out_blocks": "0", "process_user_time": 1.12002}
[0m15:49:57.755149 [debug] [MainThread]: Command `dbt build` failed at 15:49:57.754706 after 0.11 seconds
[0m15:49:57.757908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d694daa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d6cdd4d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8d6cdd42d0>]}
[0m15:49:57.758850 [debug] [MainThread]: Flushing usage events
[0m15:49:58.131106 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:52:15.898631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec7599c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec7401010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec7401fd0>]}


============================== 15:52:15.904238 | 0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8 ==============================
[0m15:52:15.904238 [info ] [MainThread]: Running with dbt=1.9.3
[0m15:52:15.906953 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/root/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:52:15.980427 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `source-paths` config has been renamed to `model-paths`. Please update your
`dbt_project.yml` configuration to reflect this change.
[0m15:52:15.982443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec5ccfdd0>]}
[0m15:52:16.079658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec74c1550>]}
[0m15:52:16.132207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec9808110>]}
[0m15:52:16.135224 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:52:16.215814 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m15:52:16.222138 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:52:16.223122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec5afa590>]}
[0m15:52:16.915012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec5b23910>]}
[0m15:52:16.970003 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/target/manifest.json
[0m15:52:16.976821 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/target/semantic_manifest.json
[0m15:52:17.017532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0bb2e2e1-338e-4e07-bf89-4a7aa954cdf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec583b610>]}
[0m15:52:17.018669 [info ] [MainThread]: Found 433 macros
[0m15:52:17.023529 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m15:52:17.027508 [debug] [MainThread]: Command end result
[0m15:52:17.067548 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/target/manifest.json
[0m15:52:17.072175 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/target/semantic_manifest.json
[0m15:52:17.078068 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/target/run_results.json
[0m15:52:17.080278 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 1.2436041, "process_in_blocks": "0", "process_kernel_time": 0.165775, "process_mem_max_rss": "102264", "process_out_blocks": "120", "process_user_time": 2.258693}
[0m15:52:17.081187 [debug] [MainThread]: Command `dbt build` succeeded at 15:52:17.081074 after 1.24 seconds
[0m15:52:17.082094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcec740bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcecaef0c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcecaef0c90>]}
[0m15:52:17.082958 [debug] [MainThread]: Flushing usage events
[0m15:52:17.530092 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:53:29.519937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c387af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c3b73210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c376b590>]}


============================== 15:53:29.526649 | 2594c392-d711-4664-b4f3-c68fde9f2368 ==============================
[0m15:53:29.526649 [info ] [MainThread]: Running with dbt=1.9.3
[0m15:53:29.528409 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/root/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:53:29.672574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2594c392-d711-4664-b4f3-c68fde9f2368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c35fd310>]}
[0m15:53:29.719370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2594c392-d711-4664-b4f3-c68fde9f2368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c59f83d0>]}
[0m15:53:29.721229 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:53:29.772668 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m15:53:29.823454 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:53:29.825119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2594c392-d711-4664-b4f3-c68fde9f2368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c457c890>]}
[0m15:53:30.495381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2594c392-d711-4664-b4f3-c68fde9f2368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c1d1b450>]}
[0m15:53:30.558194 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/target/manifest.json
[0m15:53:30.566348 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/target/semantic_manifest.json
[0m15:53:30.594869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2594c392-d711-4664-b4f3-c68fde9f2368', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c1a85d10>]}
[0m15:53:30.596645 [info ] [MainThread]: Found 433 macros
[0m15:53:30.602276 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m15:53:30.606316 [debug] [MainThread]: Command end result
[0m15:53:30.645856 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/target/manifest.json
[0m15:53:30.652081 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/target/semantic_manifest.json
[0m15:53:30.658680 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/target/run_results.json
[0m15:53:30.660191 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 1.2152436, "process_in_blocks": "0", "process_kernel_time": 0.111144, "process_mem_max_rss": "102336", "process_out_blocks": "0", "process_user_time": 2.101643}
[0m15:53:30.661034 [debug] [MainThread]: Command `dbt build` succeeded at 15:53:30.660928 after 1.22 seconds
[0m15:53:30.661773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c37db690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c379fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c70ec290>]}
[0m15:53:30.663539 [debug] [MainThread]: Flushing usage events
[0m15:53:31.079143 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:34:09.862941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc6294910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc67ad6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc6296190>]}


============================== 06:34:09.882528 | 62a9f0e3-b9bc-4eb9-9d85-15c6cf3fc9da ==============================
[0m06:34:09.882528 [info ] [MainThread]: Running with dbt=1.9.3
[0m06:34:09.888617 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'profiles_dir': '/root/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:34:10.164593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62a9f0e3-b9bc-4eb9-9d85-15c6cf3fc9da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc6f83910>]}
[0m06:34:10.255655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '62a9f0e3-b9bc-4eb9-9d85-15c6cf3fc9da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc85044d0>]}
[0m06:34:10.259175 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:34:10.378517 [debug] [MainThread]: checksum: 5671c00892cdbcef29c3b00cc5ba7510c3d18a35c883caeb9ab9ee266dc29c8f, vars: {}, profile: , target: , version: 1.9.3
[0m06:34:10.525874 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:34:10.528181 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:34:10.541071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62a9f0e3-b9bc-4eb9-9d85-15c6cf3fc9da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc6105910>]}
[0m06:34:10.660627 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/target/manifest.json
[0m06:34:10.675906 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/target/semantic_manifest.json
[0m06:34:10.800505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62a9f0e3-b9bc-4eb9-9d85-15c6cf3fc9da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc43c6d90>]}
[0m06:34:10.803122 [info ] [MainThread]: Found 433 macros
[0m06:34:10.807694 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m06:34:10.812799 [debug] [MainThread]: Command end result
[0m06:34:10.872343 [debug] [MainThread]: Wrote artifact WritableManifest to /usr/app/target/manifest.json
[0m06:34:10.882526 [debug] [MainThread]: Wrote artifact SemanticManifest to /usr/app/target/semantic_manifest.json
[0m06:34:10.895624 [debug] [MainThread]: Wrote artifact RunExecutionResult to /usr/app/target/run_results.json
[0m06:34:10.899415 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 1.1831601, "process_in_blocks": "0", "process_kernel_time": 0.424192, "process_mem_max_rss": "102352", "process_out_blocks": "0", "process_user_time": 2.63605}
[0m06:34:10.901550 [debug] [MainThread]: Command `dbt build` succeeded at 06:34:10.901298 after 1.19 seconds
[0m06:34:10.903259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc60fe150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc9d61750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc47e9510>]}
[0m06:34:10.904721 [debug] [MainThread]: Flushing usage events
[0m06:34:11.608594 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:47:35.746238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232ADA17050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232ADA17020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AD9C4DD0>]}


============================== 11:47:35.760719 | 75bcf745-6a8e-4256-813e-24b2afbcad44 ==============================
[0m11:47:35.760719 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:47:35.762480 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:47:36.070029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '75bcf745-6a8e-4256-813e-24b2afbcad44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232ADA6D9D0>]}
[0m11:47:36.148814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '75bcf745-6a8e-4256-813e-24b2afbcad44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AE9EDB50>]}
[0m11:47:36.152658 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:47:36.498188 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:47:36.548444 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m11:47:36.548444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '75bcf745-6a8e-4256-813e-24b2afbcad44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AE042C90>]}
[0m11:47:37.488500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75bcf745-6a8e-4256-813e-24b2afbcad44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AD07FB00>]}
[0m11:47:37.550414 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m11:47:37.553539 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m11:47:37.608891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75bcf745-6a8e-4256-813e-24b2afbcad44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AFD4D6A0>]}
[0m11:47:37.608891 [info ] [MainThread]: Found 433 macros
[0m11:47:37.611240 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m11:47:37.611240 [debug] [MainThread]: Command end result
[0m11:47:37.638132 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m11:47:37.642242 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m11:47:37.643990 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Project\DataPipeline\dags\dbt_project\target\run_results.json
[0m11:47:37.643990 [debug] [MainThread]: Command `dbt build` succeeded at 11:47:37.643990 after 2.26 seconds
[0m11:47:37.643990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AFBCCA70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AD989D00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000232AFD3C2C0>]}
[0m11:47:37.643990 [debug] [MainThread]: Flushing usage events
[0m11:47:38.339901 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:12:54.148378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269774C3C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269774C3CB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269774C3BC0>]}


============================== 12:12:54.156819 | 40a90560-5014-4d42-94e0-b1e26b57da07 ==============================
[0m12:12:54.156819 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:12:54.156819 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m12:12:54.511965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '40a90560-5014-4d42-94e0-b1e26b57da07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000269775311F0>]}
[0m12:12:54.599412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '40a90560-5014-4d42-94e0-b1e26b57da07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026977AA0440>]}
[0m12:12:54.599412 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:12:54.952706 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m12:12:55.082244 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:12:55.082244 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:12:55.091187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40a90560-5014-4d42-94e0-b1e26b57da07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026978B0C410>]}
[0m12:12:55.142606 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m12:12:55.151450 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m12:12:55.214977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40a90560-5014-4d42-94e0-b1e26b57da07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026978B35490>]}
[0m12:12:55.214977 [info ] [MainThread]: Found 433 macros
[0m12:12:55.214977 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:12:55.214977 [debug] [MainThread]: Command end result
[0m12:12:55.242896 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m12:12:55.249444 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m12:12:55.249444 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Project\DataPipeline\dags\dbt_project\target\run_results.json
[0m12:12:55.256266 [debug] [MainThread]: Command `dbt build` succeeded at 12:12:55.256266 after 1.48 seconds
[0m12:12:55.258431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026977A0CFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026978B01E80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026978B03500>]}
[0m12:12:55.258431 [debug] [MainThread]: Flushing usage events
[0m12:12:55.624546 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:48.162916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C9086F30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C9086E40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C9B2FC20>]}


============================== 12:40:48.172520 | b4abb57e-dc75-432a-9de5-c66d682406aa ==============================
[0m12:40:48.172520 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:40:48.173580 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt build', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:40:48.612421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4abb57e-dc75-432a-9de5-c66d682406aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C9C9DC70>]}
[0m12:40:48.716510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4abb57e-dc75-432a-9de5-c66d682406aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C8A68620>]}
[0m12:40:48.725882 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:40:49.165970 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m12:40:49.275232 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:40:49.276286 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:40:49.283426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b4abb57e-dc75-432a-9de5-c66d682406aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228CA1C5550>]}
[0m12:40:49.320584 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m12:40:49.333395 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m12:40:49.608564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b4abb57e-dc75-432a-9de5-c66d682406aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228CB771EB0>]}
[0m12:40:49.609187 [info ] [MainThread]: Found 433 macros
[0m12:40:49.611746 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:40:49.614187 [debug] [MainThread]: Command end result
[0m12:40:49.635251 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m12:40:49.638539 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m12:40:49.644851 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Project\DataPipeline\dags\dbt_project\target\run_results.json
[0m12:40:49.646638 [debug] [MainThread]: Command `dbt build` succeeded at 12:40:49.646254 after 1.85 seconds
[0m12:40:49.646982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C93DEEA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228C9368560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228CB37F950>]}
[0m12:40:49.646982 [debug] [MainThread]: Flushing usage events
[0m12:40:50.012377 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:40:32.256868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCE3A6E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCE2B3B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCB71FAD0>]}


============================== 04:40:32.261622 | defed430-f847-482a-8614-e44e89ea1320 ==============================
[0m04:40:32.261622 [info ] [MainThread]: Running with dbt=1.9.6
[0m04:40:32.261622 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt build --project-dir C:\\Project\\DataPipeline\\dags\\dbt_project', 'send_anonymous_usage_stats': 'True'}
[0m04:40:32.461867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'defed430-f847-482a-8614-e44e89ea1320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCB954410>]}
[0m04:40:32.525350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'defed430-f847-482a-8614-e44e89ea1320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCE820C50>]}
[0m04:40:32.525350 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:40:32.694696 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m04:40:32.725307 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m04:40:32.725307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'defed430-f847-482a-8614-e44e89ea1320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCE3A6720>]}
[0m04:40:33.323070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'defed430-f847-482a-8614-e44e89ea1320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FD00675F0>]}
[0m04:40:33.353329 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m04:40:33.353329 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m04:40:33.447998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'defed430-f847-482a-8614-e44e89ea1320', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FD0066D20>]}
[0m04:40:33.447998 [info ] [MainThread]: Found 433 macros
[0m04:40:33.447998 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m04:40:33.447998 [debug] [MainThread]: Command end result
[0m04:40:33.463740 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m04:40:33.463740 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m04:40:33.463740 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Project\DataPipeline\dags\dbt_project\target\run_results.json
[0m04:40:33.463740 [debug] [MainThread]: Command `dbt build` succeeded at 04:40:33.463740 after 1.41 seconds
[0m04:40:33.463740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCE318140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCDCB2120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FCDCB1400>]}
[0m04:40:33.463740 [debug] [MainThread]: Flushing usage events
[0m04:40:33.887203 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:45:22.326974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002982DD963F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298314EACF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298314E92E0>]}


============================== 04:45:22.331343 | 8da6c4b5-9029-4879-a4a3-8266baa7e971 ==============================
[0m04:45:22.331343 [info ] [MainThread]: Running with dbt=1.9.6
[0m04:45:22.331343 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build --project-dir C:\\Project\\DataPipeline\\dags\\dbt_project', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:45:22.512532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8da6c4b5-9029-4879-a4a3-8266baa7e971', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029831812330>]}
[0m04:45:22.586901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8da6c4b5-9029-4879-a4a3-8266baa7e971', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029832C16A80>]}
[0m04:45:22.586901 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:45:22.799113 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m04:45:22.824405 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m04:45:22.824405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8da6c4b5-9029-4879-a4a3-8266baa7e971', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002983330F2F0>]}
[0m04:45:23.307970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8da6c4b5-9029-4879-a4a3-8266baa7e971', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002983339AD20>]}
[0m04:45:23.330846 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m04:45:23.332852 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m04:45:23.360318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8da6c4b5-9029-4879-a4a3-8266baa7e971', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298333A6930>]}
[0m04:45:23.360318 [info ] [MainThread]: Found 433 macros
[0m04:45:23.362335 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m04:45:23.362335 [debug] [MainThread]: Command end result
[0m04:45:23.372982 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m04:45:23.376313 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m04:45:23.380493 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Project\DataPipeline\dags\dbt_project\target\run_results.json
[0m04:45:23.380493 [debug] [MainThread]: Command `dbt build` succeeded at 04:45:23.380493 after 1.24 seconds
[0m04:45:23.381626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002982DD963F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002982B719A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000298318E7620>]}
[0m04:45:23.383923 [debug] [MainThread]: Flushing usage events
[0m04:45:23.797373 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:48:45.494263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8E9356D20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8E8C62270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8E93569F0>]}


============================== 04:48:45.497919 | 77daa29f-0b47-4261-8a70-65b091830c85 ==============================
[0m04:48:45.497919 [info ] [MainThread]: Running with dbt=1.9.6
[0m04:48:45.498451 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt build --project-dir C:\\Project\\DataPipeline\\dags\\dbt_project', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:48:45.626297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '77daa29f-0b47-4261-8a70-65b091830c85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EA8E3CE0>]}
[0m04:48:45.700531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '77daa29f-0b47-4261-8a70-65b091830c85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8E9639D00>]}
[0m04:48:45.700531 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:48:45.900727 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m04:48:45.934062 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m04:48:45.936960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '77daa29f-0b47-4261-8a70-65b091830c85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8E93565D0>]}
[0m04:48:46.819901 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_pipeline.raw_to_normalized' (../../models\raw_to_normalized.sql) depends on a source named 'raw.raw_data' which was not found
[0m04:48:46.819901 [debug] [MainThread]: Command `dbt build` failed at 04:48:46.819901 after 1.50 seconds
[0m04:48:46.819901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8E97AB5C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EB1D02C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8EB256240>]}
[0m04:48:46.819901 [debug] [MainThread]: Flushing usage events
[0m04:48:47.238159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:00:01.823459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002090F0BDC10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020911EB73B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020911EB4B00>]}


============================== 05:00:01.826353 | 6f92e768-44e0-4c69-9869-94e4953ff19c ==============================
[0m05:00:01.826353 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:00:01.826353 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build --project-dir C:\\Project\\DataPipeline\\dags\\dbt_project', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:00:01.969232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f92e768-44e0-4c69-9869-94e4953ff19c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209136A9580>]}
[0m05:00:02.018064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f92e768-44e0-4c69-9869-94e4953ff19c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020912217770>]}
[0m05:00:02.018064 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:00:02.208140 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m05:00:02.238574 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:00:02.239764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6f92e768-44e0-4c69-9869-94e4953ff19c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002091396EF60>]}
[0m05:00:03.233558 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_pipeline.raw_to_normalized' (../../models\raw_to_normalized.sql) depends on a source named 'raw.raw_data' which was not found
[0m05:00:03.233558 [debug] [MainThread]: Command `dbt build` failed at 05:00:03.233558 after 1.60 seconds
[0m05:00:03.233558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020911F8DBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020911301550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209139E8E30>]}
[0m05:00:03.233558 [debug] [MainThread]: Flushing usage events
[0m05:00:03.656274 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:02:04.613108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F78174C20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7BCA6BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7BCA4CE0>]}


============================== 05:02:04.617183 | a2fc53bb-7365-49f2-b3a0-4f80bc671ae2 ==============================
[0m05:02:04.617183 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:02:04.617183 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m05:02:04.762270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2fc53bb-7365-49f2-b3a0-4f80bc671ae2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F79254320>]}
[0m05:02:04.804081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2fc53bb-7365-49f2-b3a0-4f80bc671ae2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7947FAD0>]}
[0m05:02:04.804081 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:02:04.966689 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m05:02:04.992974 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:02:04.992974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a2fc53bb-7365-49f2-b3a0-4f80bc671ae2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7D927F20>]}
[0m05:02:06.047869 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_pipeline.raw_to_normalized' (../../models\raw_to_normalized.sql) depends on a source named 'raw.raw_data' which was not found
[0m05:02:06.047869 [debug] [MainThread]: Command `dbt build` failed at 05:02:06.047869 after 1.77 seconds
[0m05:02:06.047869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7901FC20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7B63DCD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F7DAC8980>]}
[0m05:02:06.047869 [debug] [MainThread]: Flushing usage events
[0m05:02:06.474083 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:03:27.699819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002026FF366C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002026D9C74D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202707EC440>]}


============================== 05:03:27.701827 | a3d9a0d6-1da8-4857-abb2-44b92716f22f ==============================
[0m05:03:27.701827 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:03:27.701827 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt list --resource-type source', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:03:27.836619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3d9a0d6-1da8-4857-abb2-44b92716f22f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202709C34A0>]}
[0m05:03:27.886431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3d9a0d6-1da8-4857-abb2-44b92716f22f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020271B54860>]}
[0m05:03:27.888438 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:03:28.112181 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m05:03:28.148208 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:03:28.150217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a3d9a0d6-1da8-4857-abb2-44b92716f22f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202721FB7D0>]}
[0m05:03:29.206145 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.data_pipeline.raw_to_normalized' (../../models\raw_to_normalized.sql) depends on a source named 'raw.raw_data' which was not found
[0m05:03:29.217687 [debug] [MainThread]: Command `dbt list` failed at 05:03:29.217687 after 1.73 seconds
[0m05:03:29.219702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202706E9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000202723768A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002026F9A6120>]}
[0m05:03:29.219702 [debug] [MainThread]: Flushing usage events
[0m05:03:29.630835 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:04:33.377385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002405FBC7080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024062722600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000240627215B0>]}


============================== 05:04:33.381251 | 5220d0e3-241a-47a7-a30c-9fab1382aa5b ==============================
[0m05:04:33.381251 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:04:33.383255 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:04:33.537828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5220d0e3-241a-47a7-a30c-9fab1382aa5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002405FBC7080>]}
[0m05:04:33.608848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5220d0e3-241a-47a7-a30c-9fab1382aa5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000240628A1C70>]}
[0m05:04:33.609850 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:04:33.872634 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m05:04:33.910043 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:04:33.911062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5220d0e3-241a-47a7-a30c-9fab1382aa5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000240627466C0>]}
[0m05:04:34.947580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5220d0e3-241a-47a7-a30c-9fab1382aa5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000240643E5760>]}
[0m05:04:35.004983 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m05:04:35.004983 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m05:04:35.055385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5220d0e3-241a-47a7-a30c-9fab1382aa5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024063DE7740>]}
[0m05:04:35.055924 [info ] [MainThread]: Found 1 model, 21 data tests, 3 sources, 433 macros
[0m05:04:35.061956 [info ] [MainThread]: 
[0m05:04:35.062461 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m05:04:35.065806 [info ] [MainThread]: 
[0m05:04:35.065806 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m05:04:35.071818 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datamart'
[0m05:04:35.163037 [debug] [ThreadPool]: Using postgres connection "list_datamart"
[0m05:04:35.163621 [debug] [ThreadPool]: On list_datamart: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "connection_name": "list_datamart"} */

    select distinct nspname from pg_namespace
  
[0m05:04:35.163621 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:04:37.871039 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "postgres_dw" to address: No such host is known. 

[0m05:04:40.550111 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "connection_name": "list_datamart"} */

    select distinct nspname from pg_namespace
  
[0m05:04:40.552116 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m05:04:40.552116 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m05:04:40.554122 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m05:04:40.554122 [debug] [ThreadPool]: On list_datamart: No close available on handle
[0m05:04:40.556128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:04:40.556128 [debug] [MainThread]: Connection 'list_datamart' was properly closed.
[0m05:04:40.556128 [info ] [MainThread]: 
[0m05:04:40.558134 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 5.49 seconds (5.49s).
[0m05:04:40.558134 [error] [MainThread]: Encountered an error:
Database Error
  could not translate host name "postgres_dw" to address: No such host is known. 
  
[0m05:04:40.562145 [debug] [MainThread]: Command `dbt build` failed at 05:04:40.562145 after 7.36 seconds
[0m05:04:40.562145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024061BA5CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024063DE5F40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024062780BF0>]}
[0m05:04:40.562145 [debug] [MainThread]: Flushing usage events
[0m05:04:40.945480 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:13:15.683405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7F2376C00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7F24D1280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7F1D623F0>]}


============================== 05:13:15.684222 | 9b95d384-d9cd-4efe-8429-4566bca48e79 ==============================
[0m05:13:15.684222 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:13:15.687772 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m05:13:15.702634 [info ] [MainThread]: dbt version: 1.9.6
[0m05:13:15.702634 [info ] [MainThread]: python version: 3.12.6
[0m05:13:15.702634 [info ] [MainThread]: python path: C:\Project\DataPipeline\venv\Scripts\python.exe
[0m05:13:15.703708 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m05:13:15.742996 [info ] [MainThread]: Using profiles dir at C:\Users\Gaurav Chugh\.dbt
[0m05:13:15.746837 [info ] [MainThread]: Using profiles.yml file at C:\Users\Gaurav Chugh\.dbt\profiles.yml
[0m05:13:15.746837 [info ] [MainThread]: Using dbt_project.yml file at C:\Project\DataPipeline\dags\dbt_project\dbt_project.yml
[0m05:13:15.747853 [info ] [MainThread]: adapter type: postgres
[0m05:13:15.748849 [info ] [MainThread]: adapter version: 1.9.0
[0m05:13:15.830953 [info ] [MainThread]: Configuration:
[0m05:13:15.835971 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m05:13:15.835971 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m05:13:15.835971 [info ] [MainThread]: Required dependencies:
[0m05:13:15.835971 [debug] [MainThread]: Executing "git --help"
[0m05:13:15.875048 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m05:13:15.876049 [debug] [MainThread]: STDERR: "b''"
[0m05:13:15.876049 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m05:13:15.876049 [info ] [MainThread]: Connection:
[0m05:13:15.877051 [info ] [MainThread]:   host: localhost
[0m05:13:15.877051 [info ] [MainThread]:   port: 5432
[0m05:13:15.877051 [info ] [MainThread]:   user: dwh_user
[0m05:13:15.878049 [info ] [MainThread]:   database: datamart
[0m05:13:15.878049 [info ] [MainThread]:   schema: public
[0m05:13:15.879049 [info ] [MainThread]:   connect_timeout: 10
[0m05:13:15.879049 [info ] [MainThread]:   role: None
[0m05:13:15.879049 [info ] [MainThread]:   search_path: None
[0m05:13:15.879049 [info ] [MainThread]:   keepalives_idle: 0
[0m05:13:15.880048 [info ] [MainThread]:   sslmode: None
[0m05:13:15.880048 [info ] [MainThread]:   sslcert: None
[0m05:13:15.881048 [info ] [MainThread]:   sslkey: None
[0m05:13:15.881048 [info ] [MainThread]:   sslrootcert: None
[0m05:13:15.881048 [info ] [MainThread]:   application_name: dbt
[0m05:13:15.882048 [info ] [MainThread]:   retries: 1
[0m05:13:15.882048 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:13:16.021640 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m05:13:16.089851 [debug] [MainThread]: Using postgres connection "debug"
[0m05:13:16.094228 [debug] [MainThread]: On debug: select 1 as id
[0m05:13:16.094228 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:13:16.193928 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"

[0m05:13:16.242148 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m05:13:16.242148 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m05:13:16.243694 [debug] [MainThread]: On debug: No close available on handle
[0m05:13:16.243694 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m05:13:16.243694 [info ] [MainThread]: [31m1 check failed:[0m
[0m05:13:16.243694 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m05:13:16.243694 [debug] [MainThread]: Command `dbt debug` failed at 05:13:16.243694 after 0.73 seconds
[0m05:13:16.243694 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m05:13:16.243694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7F23B2630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7F25E0CE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7F25E1A00>]}
[0m05:13:16.243694 [debug] [MainThread]: Flushing usage events
[0m05:13:16.644318 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:15:04.130765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001653FA51A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001653CFFCAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016540511400>]}


============================== 05:15:04.139506 | 3c44796f-a673-46ce-b2fc-d6ceb2f41d5f ==============================
[0m05:15:04.139506 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:15:04.140013 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:15:04.157986 [info ] [MainThread]: dbt version: 1.9.6
[0m05:15:04.159003 [info ] [MainThread]: python version: 3.12.6
[0m05:15:04.159999 [info ] [MainThread]: python path: C:\Project\DataPipeline\venv\Scripts\python.exe
[0m05:15:04.161332 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m05:15:04.216188 [info ] [MainThread]: Using profiles dir at C:\Users\Gaurav Chugh\.dbt
[0m05:15:04.216188 [info ] [MainThread]: Using profiles.yml file at C:\Users\Gaurav Chugh\.dbt\profiles.yml
[0m05:15:04.216188 [info ] [MainThread]: Using dbt_project.yml file at C:\Project\DataPipeline\dags\dbt_project\dbt_project.yml
[0m05:15:04.216188 [info ] [MainThread]: adapter type: postgres
[0m05:15:04.216188 [info ] [MainThread]: adapter version: 1.9.0
[0m05:15:04.353101 [info ] [MainThread]: Configuration:
[0m05:15:04.356308 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m05:15:04.356308 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m05:15:04.356967 [info ] [MainThread]: Required dependencies:
[0m05:15:04.357677 [debug] [MainThread]: Executing "git --help"
[0m05:15:04.388965 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m05:15:04.389492 [debug] [MainThread]: STDERR: "b''"
[0m05:15:04.390015 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m05:15:04.390354 [info ] [MainThread]: Connection:
[0m05:15:04.391357 [info ] [MainThread]:   host: localhost
[0m05:15:04.391357 [info ] [MainThread]:   port: 5432
[0m05:15:04.391867 [info ] [MainThread]:   user: dwh_user
[0m05:15:04.391867 [info ] [MainThread]:   database: datamart
[0m05:15:04.392872 [info ] [MainThread]:   schema: public
[0m05:15:04.393375 [info ] [MainThread]:   connect_timeout: 10
[0m05:15:04.393375 [info ] [MainThread]:   role: None
[0m05:15:04.393375 [info ] [MainThread]:   search_path: None
[0m05:15:04.393375 [info ] [MainThread]:   keepalives_idle: 0
[0m05:15:04.394379 [info ] [MainThread]:   sslmode: None
[0m05:15:04.394379 [info ] [MainThread]:   sslcert: None
[0m05:15:04.394379 [info ] [MainThread]:   sslkey: None
[0m05:15:04.394379 [info ] [MainThread]:   sslrootcert: None
[0m05:15:04.395380 [info ] [MainThread]:   application_name: dbt
[0m05:15:04.395380 [info ] [MainThread]:   retries: 1
[0m05:15:04.396381 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:15:04.550624 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m05:15:04.598601 [debug] [MainThread]: Using postgres connection "debug"
[0m05:15:04.598601 [debug] [MainThread]: On debug: select 1 as id
[0m05:15:04.598601 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:15:04.661520 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"

[0m05:15:04.711324 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m05:15:04.711324 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m05:15:04.713330 [debug] [MainThread]: On debug: No close available on handle
[0m05:15:04.713330 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m05:15:04.714506 [info ] [MainThread]: [31m1 check failed:[0m
[0m05:15:04.715502 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m05:15:04.716303 [debug] [MainThread]: Command `dbt debug` failed at 05:15:04.716303 after 0.80 seconds
[0m05:15:04.716303 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m05:15:04.716303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001653CFFCAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016540762A80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016540216870>]}
[0m05:15:04.716303 [debug] [MainThread]: Flushing usage events
[0m05:15:05.078607 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:16:20.273321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F8BB7FA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F8BB7C380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F91A95F10>]}


============================== 05:16:20.274334 | 538f267f-e6e9-469e-a327-116c19b7653c ==============================
[0m05:16:20.274334 [info ] [MainThread]: Running with dbt=1.9.6
[0m05:16:20.274334 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m05:16:20.293732 [info ] [MainThread]: dbt version: 1.9.6
[0m05:16:20.293732 [info ] [MainThread]: python version: 3.12.6
[0m05:16:20.295740 [info ] [MainThread]: python path: C:\Project\DataPipeline\venv\Scripts\python.exe
[0m05:16:20.296254 [info ] [MainThread]: os info: Windows-11-10.0.26100-SP0
[0m05:16:20.343041 [info ] [MainThread]: Using profiles dir at C:\Users\Gaurav Chugh\.dbt
[0m05:16:20.344053 [info ] [MainThread]: Using profiles.yml file at C:\Users\Gaurav Chugh\.dbt\profiles.yml
[0m05:16:20.345053 [info ] [MainThread]: Using dbt_project.yml file at C:\Project\DataPipeline\dags\dbt_project\dbt_project.yml
[0m05:16:20.346053 [info ] [MainThread]: adapter type: postgres
[0m05:16:20.347053 [info ] [MainThread]: adapter version: 1.9.0
[0m05:16:20.418699 [info ] [MainThread]: Configuration:
[0m05:16:20.418699 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m05:16:20.418699 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m05:16:20.418699 [info ] [MainThread]: Required dependencies:
[0m05:16:20.418699 [debug] [MainThread]: Executing "git --help"
[0m05:16:20.449237 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m05:16:20.450720 [debug] [MainThread]: STDERR: "b''"
[0m05:16:20.451726 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m05:16:20.451726 [info ] [MainThread]: Connection:
[0m05:16:20.452725 [info ] [MainThread]:   host: localhost
[0m05:16:20.453422 [info ] [MainThread]:   port: 5432
[0m05:16:20.453422 [info ] [MainThread]:   user: dwh_user
[0m05:16:20.453422 [info ] [MainThread]:   database: datamart
[0m05:16:20.453422 [info ] [MainThread]:   schema: public
[0m05:16:20.453422 [info ] [MainThread]:   connect_timeout: 10
[0m05:16:20.453422 [info ] [MainThread]:   role: None
[0m05:16:20.453422 [info ] [MainThread]:   search_path: None
[0m05:16:20.453422 [info ] [MainThread]:   keepalives_idle: 0
[0m05:16:20.453422 [info ] [MainThread]:   sslmode: None
[0m05:16:20.456812 [info ] [MainThread]:   sslcert: None
[0m05:16:20.457315 [info ] [MainThread]:   sslkey: None
[0m05:16:20.457650 [info ] [MainThread]:   sslrootcert: None
[0m05:16:20.457650 [info ] [MainThread]:   application_name: dbt
[0m05:16:20.460105 [info ] [MainThread]:   retries: 1
[0m05:16:20.460105 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m05:16:20.627554 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m05:16:20.676235 [debug] [MainThread]: Using postgres connection "debug"
[0m05:16:20.676235 [debug] [MainThread]: On debug: select 1 as id
[0m05:16:20.676235 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:16:20.857120 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"

[0m05:16:20.996980 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m05:16:21.006714 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m05:16:21.006714 [debug] [MainThread]: On debug: No close available on handle
[0m05:16:21.006714 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m05:16:21.006714 [info ] [MainThread]: [31m1 check failed:[0m
[0m05:16:21.009641 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m05:16:21.009641 [debug] [MainThread]: Command `dbt debug` failed at 05:16:21.009641 after 0.96 seconds
[0m05:16:21.009641 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m05:16:21.009641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F917FA720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F930177A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F91011BE0>]}
[0m05:16:21.009641 [debug] [MainThread]: Flushing usage events
[0m05:16:21.416626 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:52.926906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D44806F30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D47427EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D472F8200>]}


============================== 14:24:52.969721 | cb1a702a-78ef-46fc-acd2-e07d452915ca ==============================
[0m14:24:52.969721 [info ] [MainThread]: Running with dbt=1.9.6
[0m14:24:52.971597 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:53.495968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cb1a702a-78ef-46fc-acd2-e07d452915ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D46C924B0>]}
[0m14:24:53.626422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cb1a702a-78ef-46fc-acd2-e07d452915ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D47425730>]}
[0m14:24:53.633257 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m14:24:54.065897 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m14:24:54.231745 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m14:24:54.234021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cb1a702a-78ef-46fc-acd2-e07d452915ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D4906BD10>]}
[0m14:24:55.819216 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'customers' in the 'models' section of file '../../models\schema.yml'
[0m14:24:55.824792 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'orders' in the 'models' section of file '../../models\schema.yml'
[0m14:24:55.831039 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'products' in the 'models' section of file '../../models\schema.yml'
[0m14:24:55.838083 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'reviews' in the 'models' section of file '../../models\schema.yml'
[0m14:24:56.585150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb1a702a-78ef-46fc-acd2-e07d452915ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D492D8D70>]}
[0m14:24:56.801624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb1a702a-78ef-46fc-acd2-e07d452915ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D492CCEC0>]}
[0m14:24:56.802139 [info ] [MainThread]: Found 1 model, 18 data tests, 3 sources, 433 macros
[0m14:24:56.803444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb1a702a-78ef-46fc-acd2-e07d452915ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D49216FC0>]}
[0m14:24:56.806345 [info ] [MainThread]: 
[0m14:24:56.806955 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:56.808404 [info ] [MainThread]: 
[0m14:24:56.810051 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:24:56.811783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datamart_public'
[0m14:24:56.952788 [debug] [ThreadPool]: Using postgres connection "list_datamart_public"
[0m14:24:56.953881 [debug] [ThreadPool]: On list_datamart_public: BEGIN
[0m14:24:56.954423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:57.039181 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"

[0m14:24:57.136247 [debug] [ThreadPool]: Postgres adapter: Error running SQL: BEGIN
[0m14:24:57.137262 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m14:24:57.138260 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_relations_without_caching
[0m14:24:57.139273 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m14:24:57.139273 [debug] [ThreadPool]: On list_datamart_public: No close available on handle
[0m14:24:57.141793 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:57.142818 [debug] [MainThread]: Connection 'list_datamart_public' was properly closed.
[0m14:24:57.143807 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "localhost" (::1), port 5432 failed: FATAL:  password authentication failed for user "dwh_user"
  
[0m14:24:57.145919 [debug] [MainThread]: Command `dbt docs generate` failed at 14:24:57.145919 after 4.81 seconds
[0m14:24:57.147449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D4766CDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D492BB080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023D4925A750>]}
[0m14:24:57.147449 [debug] [MainThread]: Flushing usage events
[0m14:24:57.577918 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:35:52.375311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF80A6F00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF8A551C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF8A54EC0>]}


============================== 23:35:52.397321 | d1557795-d657-4908-bcd3-d754ef2fb93c ==============================
[0m23:35:52.397321 [info ] [MainThread]: Running with dbt=1.9.6
[0m23:35:52.399830 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Project\\DataPipeline\\dags\\dbt_project\\logs', 'profiles_dir': 'C:\\Users\\Gaurav Chugh\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build --project-dir C:\\Project\\DataPipeline\\dags\\dbt_project', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:35:52.895484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd1557795-d657-4908-bcd3-d754ef2fb93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFC1671A0>]}
[0m23:35:53.009732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd1557795-d657-4908-bcd3-d754ef2fb93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFC235EB0>]}
[0m23:35:53.017769 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:35:53.570644 [debug] [MainThread]: checksum: dd6dc1e5178459e3de3bf2eeb7c86bed4be2266c311fce8c15d86eb4ff94e7ad, vars: {}, profile: , target: , version: 1.9.6
[0m23:35:53.891823 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:35:53.893431 [debug] [MainThread]: Partial parsing: updated file: data_pipeline://../../models\customers.yml
[0m23:35:54.021143 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'orders' in the 'models' section of file '../../models\customers.yml'
[0m23:35:54.028435 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'products' in the 'models' section of file '../../models\customers.yml'
[0m23:35:54.033436 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'reviews' in the 'models' section of file '../../models\customers.yml'
[0m23:35:54.038499 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'customers' in the 'models' section of file '../../models\customers.yml'
[0m23:35:54.197358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1557795-d657-4908-bcd3-d754ef2fb93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFC2C6FC0>]}
[0m23:35:54.337139 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m23:35:54.353408 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m23:35:54.656322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1557795-d657-4908-bcd3-d754ef2fb93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFC2F23C0>]}
[0m23:35:54.657839 [info ] [MainThread]: Found 1 model, 18 data tests, 3 sources, 433 macros
[0m23:35:54.663458 [info ] [MainThread]: 
[0m23:35:54.664459 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:35:54.665463 [info ] [MainThread]: 
[0m23:35:54.666975 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:35:54.669499 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datamart'
[0m23:35:54.921821 [debug] [ThreadPool]: Using postgres connection "list_datamart"
[0m23:35:54.924072 [debug] [ThreadPool]: On list_datamart: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "connection_name": "list_datamart"} */

    select distinct nspname from pg_namespace
  
[0m23:35:54.925098 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:55.025551 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.100 seconds
[0m23:35:55.027302 [debug] [ThreadPool]: On list_datamart: Close
[0m23:35:55.030644 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datamart_public'
[0m23:35:55.038173 [debug] [ThreadPool]: Using postgres connection "list_datamart_public"
[0m23:35:55.038704 [debug] [ThreadPool]: On list_datamart_public: BEGIN
[0m23:35:55.038704 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:55.061555 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m23:35:55.062112 [debug] [ThreadPool]: Using postgres connection "list_datamart_public"
[0m23:35:55.062661 [debug] [ThreadPool]: On list_datamart_public: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "connection_name": "list_datamart_public"} */
select
      'datamart' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'datamart' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'datamart' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m23:35:55.094146 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.031 seconds
[0m23:35:55.095799 [debug] [ThreadPool]: On list_datamart_public: ROLLBACK
[0m23:35:55.097994 [debug] [ThreadPool]: On list_datamart_public: Close
[0m23:35:55.106664 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:55.107766 [debug] [MainThread]: On master: BEGIN
[0m23:35:55.108327 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:35:55.155977 [debug] [MainThread]: SQL status: BEGIN in 0.048 seconds
[0m23:35:55.157115 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:55.157819 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:35:55.178034 [debug] [MainThread]: SQL status: SELECT 0 in 0.020 seconds
[0m23:35:55.181230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1557795-d657-4908-bcd3-d754ef2fb93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFC879D90>]}
[0m23:35:55.182934 [debug] [MainThread]: On master: ROLLBACK
[0m23:35:55.186318 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:55.186871 [debug] [MainThread]: On master: BEGIN
[0m23:35:55.191180 [debug] [MainThread]: SQL status: BEGIN in 0.003 seconds
[0m23:35:55.191735 [debug] [MainThread]: On master: COMMIT
[0m23:35:55.192272 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:55.192801 [debug] [MainThread]: On master: COMMIT
[0m23:35:55.196005 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m23:35:55.196592 [debug] [MainThread]: On master: Close
[0m23:35:55.228578 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6
[0m23:35:55.230416 [info ] [Thread-1 (]: 1 of 19 START test source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer  [RUN]
[0m23:35:55.232588 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6'
[0m23:35:55.233269 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6
[0m23:35:55.266428 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6"
[0m23:35:55.269970 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6
[0m23:35:55.298656 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6"
[0m23:35:55.299663 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6"
[0m23:35:55.301174 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6: BEGIN
[0m23:35:55.303042 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:35:55.329048 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m23:35:55.329582 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6"
[0m23:35:55.330700 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        payment_method as value_field,
        count(*) as n_records

    from "datamart"."raw"."payments"
    group by payment_method

)

select *
from all_values
where value_field not in (
    'Credit Card','PayPal','Bank Transfer'
)



  
  
      
    ) dbt_internal_test
[0m23:35:55.333902 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.payments" does not exist
LINE 20:     from "datamart"."raw"."payments"
                  ^

[0m23:35:55.334992 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6: ROLLBACK
[0m23:35:55.337122 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6: Close
[0m23:35:55.404047 [debug] [Thread-1 (]: Database Error in test source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 20:     from "datamart"."raw"."payments"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_pay_81e9ba7a9392ec12ec328aa660bf3829.sql
[0m23:35:55.405566 [error] [Thread-1 (]: 1 of 19 ERROR source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer  [[31mERROR[0m in 0.17s]
[0m23:35:55.407077 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6
[0m23:35:55.408091 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc
[0m23:35:55.409094 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 20:     from "datamart"."raw"."payments"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_pay_81e9ba7a9392ec12ec328aa660bf3829.sql.
[0m23:35:55.410553 [info ] [Thread-1 (]: 2 of 19 START test source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending  [RUN]
[0m23:35:55.416082 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer.52bf7791a6, now test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc)
[0m23:35:55.417078 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc
[0m23:35:55.435322 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc"
[0m23:35:55.439905 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc
[0m23:35:55.447554 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc"
[0m23:35:55.450554 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc"
[0m23:35:55.451569 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc: BEGIN
[0m23:35:55.452558 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.492409 [debug] [Thread-1 (]: SQL status: BEGIN in 0.040 seconds
[0m23:35:55.493345 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc"
[0m23:35:55.494119 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        payment_status as value_field,
        count(*) as n_records

    from "datamart"."raw"."payments"
    group by payment_status

)

select *
from all_values
where value_field not in (
    'Completed','Failed','Pending'
)



  
  
      
    ) dbt_internal_test
[0m23:35:55.497515 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.payments" does not exist
LINE 20:     from "datamart"."raw"."payments"
                  ^

[0m23:35:55.498074 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc: ROLLBACK
[0m23:35:55.500449 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc: Close
[0m23:35:55.503432 [debug] [Thread-1 (]: Database Error in test source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 20:     from "datamart"."raw"."payments"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_pay_9e076b3898151400e6c50cdfdb2e3b16.sql
[0m23:35:55.504932 [error] [Thread-1 (]: 2 of 19 ERROR source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending  [[31mERROR[0m in 0.09s]
[0m23:35:55.508865 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc
[0m23:35:55.509431 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21
[0m23:35:55.513250 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 20:     from "datamart"."raw"."payments"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_pay_9e076b3898151400e6c50cdfdb2e3b16.sql.
[0m23:35:55.510961 [info ] [Thread-1 (]: 3 of 19 START test source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded  [RUN]
[0m23:35:55.514526 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending.251d1a1dcc, now test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21)
[0m23:35:55.516036 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21
[0m23:35:55.526076 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21"
[0m23:35:55.528591 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21
[0m23:35:55.531101 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21"
[0m23:35:55.533115 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21"
[0m23:35:55.533115 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21: BEGIN
[0m23:35:55.534117 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.577859 [debug] [Thread-1 (]: SQL status: BEGIN in 0.043 seconds
[0m23:35:55.578458 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21"
[0m23:35:55.579863 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        payment_status as value_field,
        count(*) as n_records

    from "datamart"."raw"."raw_data"
    group by payment_status

)

select *
from all_values
where value_field not in (
    'Paid','Pending','Refunded'
)



  
  
      
    ) dbt_internal_test
[0m23:35:55.582842 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_data" does not exist
LINE 20:     from "datamart"."raw"."raw_data"
                  ^

[0m23:35:55.583365 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21: ROLLBACK
[0m23:35:55.587330 [debug] [Thread-1 (]: On test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21: Close
[0m23:35:55.592297 [debug] [Thread-1 (]: Database Error in test source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 20:     from "datamart"."raw"."raw_data"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_raw_76585dff0454bdaee97924d29f62e64d.sql
[0m23:35:55.593308 [error] [Thread-1 (]: 3 of 19 ERROR source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded  [[31mERROR[0m in 0.08s]
[0m23:35:55.594686 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21
[0m23:35:55.595973 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9
[0m23:35:55.596986 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 20:     from "datamart"."raw"."raw_data"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_raw_76585dff0454bdaee97924d29f62e64d.sql.
[0m23:35:55.598216 [info ] [Thread-1 (]: 4 of 19 START test source_not_null_raw_payments_order_id ....................... [RUN]
[0m23:35:55.599523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded.596345ab21, now test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9)
[0m23:35:55.600180 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9
[0m23:35:55.615328 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9"
[0m23:35:55.624468 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9
[0m23:35:55.630008 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9"
[0m23:35:55.634533 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9"
[0m23:35:55.634533 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9: BEGIN
[0m23:35:55.635535 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.667927 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m23:35:55.668578 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9"
[0m23:35:55.669835 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select order_id
from "datamart"."raw"."payments"
where order_id is null



  
  
      
    ) dbt_internal_test
[0m23:35:55.673431 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.payments" does not exist
LINE 17: from "datamart"."raw"."payments"
              ^

[0m23:35:55.676027 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9: ROLLBACK
[0m23:35:55.680676 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9: Close
[0m23:35:55.685348 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_payments_order_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 17: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_payments_order_id.sql
[0m23:35:55.686362 [error] [Thread-1 (]: 4 of 19 ERROR source_not_null_raw_payments_order_id ............................ [[31mERROR[0m in 0.09s]
[0m23:35:55.687368 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9
[0m23:35:55.688380 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5
[0m23:35:55.689383 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_payments_order_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 17: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_payments_order_id.sql.
[0m23:35:55.690381 [info ] [Thread-1 (]: 5 of 19 START test source_not_null_raw_payments_payment_id ..................... [RUN]
[0m23:35:55.691629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_payments_order_id.def3cb6fc9, now test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5)
[0m23:35:55.692640 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5
[0m23:35:55.699460 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5"
[0m23:35:55.701462 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5
[0m23:35:55.707975 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5"
[0m23:35:55.709989 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5"
[0m23:35:55.711506 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5: BEGIN
[0m23:35:55.712529 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.743362 [debug] [Thread-1 (]: SQL status: BEGIN in 0.031 seconds
[0m23:35:55.744149 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5"
[0m23:35:55.744954 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select payment_id
from "datamart"."raw"."payments"
where payment_id is null



  
  
      
    ) dbt_internal_test
[0m23:35:55.748382 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.payments" does not exist
LINE 17: from "datamart"."raw"."payments"
              ^

[0m23:35:55.748382 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5: ROLLBACK
[0m23:35:55.751593 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5: Close
[0m23:35:55.756034 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_payments_payment_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 17: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_payments_payment_id.sql
[0m23:35:55.757213 [error] [Thread-1 (]: 5 of 19 ERROR source_not_null_raw_payments_payment_id .......................... [[31mERROR[0m in 0.07s]
[0m23:35:55.758424 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5
[0m23:35:55.759445 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_products_category.9265557239
[0m23:35:55.760464 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_payments_payment_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 17: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_payments_payment_id.sql.
[0m23:35:55.761456 [info ] [Thread-1 (]: 6 of 19 START test source_not_null_raw_products_category ....................... [RUN]
[0m23:35:55.762516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_payments_payment_id.a7f5b41ef5, now test.data_pipeline.source_not_null_raw_products_category.9265557239)
[0m23:35:55.763486 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_products_category.9265557239
[0m23:35:55.771339 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_products_category.9265557239"
[0m23:35:55.773433 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_products_category.9265557239
[0m23:35:55.777458 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_products_category.9265557239"
[0m23:35:55.779932 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_category.9265557239"
[0m23:35:55.779932 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_category.9265557239: BEGIN
[0m23:35:55.781448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.810028 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m23:35:55.810028 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_category.9265557239"
[0m23:35:55.811600 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_category.9265557239: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_products_category.9265557239"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select category
from "datamart"."raw"."products"
where category is null



  
  
      
    ) dbt_internal_test
[0m23:35:55.815150 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.products" does not exist
LINE 17: from "datamart"."raw"."products"
              ^

[0m23:35:55.816291 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_category.9265557239: ROLLBACK
[0m23:35:55.819455 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_category.9265557239: Close
[0m23:35:55.823691 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_products_category (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_category.sql
[0m23:35:55.824910 [error] [Thread-1 (]: 6 of 19 ERROR source_not_null_raw_products_category ............................ [[31mERROR[0m in 0.06s]
[0m23:35:55.826745 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_products_category.9265557239
[0m23:35:55.827286 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b
[0m23:35:55.828873 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_products_category.9265557239' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_products_category (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_category.sql.
[0m23:35:55.828208 [info ] [Thread-1 (]: 7 of 19 START test source_not_null_raw_products_price .......................... [RUN]
[0m23:35:55.830899 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_products_category.9265557239, now test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b)
[0m23:35:55.831922 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b
[0m23:35:55.839085 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b"
[0m23:35:55.840083 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b
[0m23:35:55.845095 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b"
[0m23:35:55.846119 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b"
[0m23:35:55.847145 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b: BEGIN
[0m23:35:55.847145 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.880470 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m23:35:55.881144 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b"
[0m23:35:55.882411 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select price
from "datamart"."raw"."products"
where price is null



  
  
      
    ) dbt_internal_test
[0m23:35:55.885003 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.products" does not exist
LINE 17: from "datamart"."raw"."products"
              ^

[0m23:35:55.886219 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b: ROLLBACK
[0m23:35:55.888234 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b: Close
[0m23:35:55.892899 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_products_price (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_price.sql
[0m23:35:55.893512 [error] [Thread-1 (]: 7 of 19 ERROR source_not_null_raw_products_price ............................... [[31mERROR[0m in 0.06s]
[0m23:35:55.895508 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b
[0m23:35:55.896340 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae
[0m23:35:55.896340 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_products_price (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_price.sql.
[0m23:35:55.898893 [info ] [Thread-1 (]: 8 of 19 START test source_not_null_raw_products_product_id ..................... [RUN]
[0m23:35:55.902515 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_products_price.ce9a7bfd3b, now test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae)
[0m23:35:55.904088 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae
[0m23:35:55.913135 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae"
[0m23:35:55.916318 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae
[0m23:35:55.922398 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae"
[0m23:35:55.922958 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae"
[0m23:35:55.925485 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae: BEGIN
[0m23:35:55.927263 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:55.958682 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m23:35:55.959273 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae"
[0m23:35:55.959978 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from "datamart"."raw"."products"
where product_id is null



  
  
      
    ) dbt_internal_test
[0m23:35:55.964343 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.products" does not exist
LINE 17: from "datamart"."raw"."products"
              ^

[0m23:35:55.966010 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae: ROLLBACK
[0m23:35:55.970937 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae: Close
[0m23:35:55.973973 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_products_product_id (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_product_id.sql
[0m23:35:55.975936 [error] [Thread-1 (]: 8 of 19 ERROR source_not_null_raw_products_product_id .......................... [[31mERROR[0m in 0.07s]
[0m23:35:55.977003 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae
[0m23:35:55.978207 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51
[0m23:35:55.980646 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_products_product_id (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_product_id.sql.
[0m23:35:55.978834 [info ] [Thread-1 (]: 9 of 19 START test source_not_null_raw_products_product_name ................... [RUN]
[0m23:35:55.982943 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_products_product_id.b984a33cae, now test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51)
[0m23:35:55.983625 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51
[0m23:35:55.994220 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51"
[0m23:35:55.996734 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51
[0m23:35:56.003229 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51"
[0m23:35:56.006320 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51"
[0m23:35:56.007323 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51: BEGIN
[0m23:35:56.008862 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.044851 [debug] [Thread-1 (]: SQL status: BEGIN in 0.036 seconds
[0m23:35:56.047839 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51"
[0m23:35:56.048984 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_name
from "datamart"."raw"."products"
where product_name is null



  
  
      
    ) dbt_internal_test
[0m23:35:56.051217 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.products" does not exist
LINE 17: from "datamart"."raw"."products"
              ^

[0m23:35:56.051781 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51: ROLLBACK
[0m23:35:56.053415 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51: Close
[0m23:35:56.056660 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_products_product_name (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_product_name.sql
[0m23:35:56.057759 [error] [Thread-1 (]: 9 of 19 ERROR source_not_null_raw_products_product_name ........................ [[31mERROR[0m in 0.07s]
[0m23:35:56.058562 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51
[0m23:35:56.058562 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3
[0m23:35:56.059577 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_products_product_name (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_product_name.sql.
[0m23:35:56.060577 [info ] [Thread-1 (]: 10 of 19 START test source_not_null_raw_raw_data_customer_id ................... [RUN]
[0m23:35:56.061596 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_products_product_name.2fb02dfa51, now test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3)
[0m23:35:56.061596 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3
[0m23:35:56.066119 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3"
[0m23:35:56.067625 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3
[0m23:35:56.069634 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3"
[0m23:35:56.071142 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3"
[0m23:35:56.072157 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3: BEGIN
[0m23:35:56.073161 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.108371 [debug] [Thread-1 (]: SQL status: BEGIN in 0.035 seconds
[0m23:35:56.108933 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3"
[0m23:35:56.109555 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_id
from "datamart"."raw"."raw_data"
where customer_id is null



  
  
      
    ) dbt_internal_test
[0m23:35:56.111831 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_data" does not exist
LINE 17: from "datamart"."raw"."raw_data"
              ^

[0m23:35:56.112919 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3: ROLLBACK
[0m23:35:56.115230 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3: Close
[0m23:35:56.118986 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_raw_data_customer_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_customer_id.sql
[0m23:35:56.120101 [error] [Thread-1 (]: 10 of 19 ERROR source_not_null_raw_raw_data_customer_id ........................ [[31mERROR[0m in 0.06s]
[0m23:35:56.120617 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3
[0m23:35:56.121241 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc
[0m23:35:56.121893 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_raw_data_customer_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_customer_id.sql.
[0m23:35:56.123055 [info ] [Thread-1 (]: 11 of 19 START test source_not_null_raw_raw_data_order_date .................... [RUN]
[0m23:35:56.123770 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_raw_data_customer_id.e7d23030b3, now test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc)
[0m23:35:56.124423 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc
[0m23:35:56.129888 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc"
[0m23:35:56.131397 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc
[0m23:35:56.135415 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc"
[0m23:35:56.136415 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc"
[0m23:35:56.137414 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc: BEGIN
[0m23:35:56.137414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.170640 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m23:35:56.171306 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc"
[0m23:35:56.172487 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select order_date
from "datamart"."raw"."raw_data"
where order_date is null



  
  
      
    ) dbt_internal_test
[0m23:35:56.175531 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_data" does not exist
LINE 17: from "datamart"."raw"."raw_data"
              ^

[0m23:35:56.176240 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc: ROLLBACK
[0m23:35:56.178879 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc: Close
[0m23:35:56.182864 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_raw_data_order_date (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_order_date.sql
[0m23:35:56.184015 [error] [Thread-1 (]: 11 of 19 ERROR source_not_null_raw_raw_data_order_date ......................... [[31mERROR[0m in 0.06s]
[0m23:35:56.185416 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc
[0m23:35:56.186039 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6
[0m23:35:56.187221 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_raw_data_order_date (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_order_date.sql.
[0m23:35:56.187810 [info ] [Thread-1 (]: 12 of 19 START test source_not_null_raw_raw_data_order_id ...................... [RUN]
[0m23:35:56.189497 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_raw_data_order_date.8fd09fb7bc, now test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6)
[0m23:35:56.190148 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6
[0m23:35:56.196209 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6"
[0m23:35:56.198745 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6
[0m23:35:56.201260 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6"
[0m23:35:56.203193 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6"
[0m23:35:56.203760 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6: BEGIN
[0m23:35:56.204309 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.226799 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m23:35:56.227462 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6"
[0m23:35:56.228365 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select order_id
from "datamart"."raw"."raw_data"
where order_id is null



  
  
      
    ) dbt_internal_test
[0m23:35:56.230549 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_data" does not exist
LINE 17: from "datamart"."raw"."raw_data"
              ^

[0m23:35:56.231106 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6: ROLLBACK
[0m23:35:56.232836 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6: Close
[0m23:35:56.236290 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_raw_data_order_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_order_id.sql
[0m23:35:56.236832 [error] [Thread-1 (]: 12 of 19 ERROR source_not_null_raw_raw_data_order_id ........................... [[31mERROR[0m in 0.05s]
[0m23:35:56.237916 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6
[0m23:35:56.238485 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e
[0m23:35:56.239042 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_raw_data_order_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_order_id.sql.
[0m23:35:56.239607 [info ] [Thread-1 (]: 13 of 19 START test source_not_null_raw_raw_data_total_amount .................. [RUN]
[0m23:35:56.240722 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_raw_data_order_id.bd97ab0ff6, now test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e)
[0m23:35:56.241284 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e
[0m23:35:56.246369 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e"
[0m23:35:56.247472 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e
[0m23:35:56.250235 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e"
[0m23:35:56.251250 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e"
[0m23:35:56.251250 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e: BEGIN
[0m23:35:56.252250 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.278680 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m23:35:56.279445 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e"
[0m23:35:56.280122 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_amount
from "datamart"."raw"."raw_data"
where total_amount is null



  
  
      
    ) dbt_internal_test
[0m23:35:56.283317 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_data" does not exist
LINE 17: from "datamart"."raw"."raw_data"
              ^

[0m23:35:56.283869 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e: ROLLBACK
[0m23:35:56.286762 [debug] [Thread-1 (]: On test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e: Close
[0m23:35:56.290376 [debug] [Thread-1 (]: Database Error in test source_not_null_raw_raw_data_total_amount (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_total_amount.sql
[0m23:35:56.290923 [error] [Thread-1 (]: 13 of 19 ERROR source_not_null_raw_raw_data_total_amount ....................... [[31mERROR[0m in 0.05s]
[0m23:35:56.292209 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e
[0m23:35:56.293307 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_positive_values_raw_products_price.d8701c9fb9
[0m23:35:56.294464 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_raw_raw_data_total_amount (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_total_amount.sql.
[0m23:35:56.294464 [info ] [Thread-1 (]: 14 of 19 START test source_positive_values_raw_products_price .................. [RUN]
[0m23:35:56.296015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_not_null_raw_raw_data_total_amount.45226b5b6e, now test.data_pipeline.source_positive_values_raw_products_price.d8701c9fb9)
[0m23:35:56.296878 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_positive_values_raw_products_price.d8701c9fb9
[0m23:35:56.327746 [debug] [Thread-1 (]: Compilation Error in test source_positive_values_raw_products_price (../../models\sources.yml)
  'test_positive_values' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m23:35:56.328932 [error] [Thread-1 (]: 14 of 19 ERROR source_positive_values_raw_products_price ....................... [[31mERROR[0m in 0.03s]
[0m23:35:56.330102 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_positive_values_raw_products_price.d8701c9fb9
[0m23:35:56.330755 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_positive_values_raw_raw_data_total_amount.fe8c89a6b3
[0m23:35:56.331314 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_positive_values_raw_products_price.d8701c9fb9' to be skipped because of status 'error'.  Reason: Compilation Error in test source_positive_values_raw_products_price (../../models\sources.yml)
  'test_positive_values' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m23:35:56.331879 [info ] [Thread-1 (]: 15 of 19 START test source_positive_values_raw_raw_data_total_amount ........... [RUN]
[0m23:35:56.332443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_positive_values_raw_products_price.d8701c9fb9, now test.data_pipeline.source_positive_values_raw_raw_data_total_amount.fe8c89a6b3)
[0m23:35:56.333019 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_positive_values_raw_raw_data_total_amount.fe8c89a6b3
[0m23:35:56.340489 [debug] [Thread-1 (]: Compilation Error in test source_positive_values_raw_raw_data_total_amount (../../models\sources.yml)
  'test_positive_values' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m23:35:56.342708 [error] [Thread-1 (]: 15 of 19 ERROR source_positive_values_raw_raw_data_total_amount ................ [[31mERROR[0m in 0.01s]
[0m23:35:56.344693 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_positive_values_raw_raw_data_total_amount.fe8c89a6b3
[0m23:35:56.345877 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533
[0m23:35:56.346443 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_positive_values_raw_raw_data_total_amount.fe8c89a6b3' to be skipped because of status 'error'.  Reason: Compilation Error in test source_positive_values_raw_raw_data_total_amount (../../models\sources.yml)
  'test_positive_values' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m23:35:56.346443 [info ] [Thread-1 (]: 16 of 19 START test source_unique_raw_payments_payment_id ...................... [RUN]
[0m23:35:56.348482 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_positive_values_raw_raw_data_total_amount.fe8c89a6b3, now test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533)
[0m23:35:56.349087 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533
[0m23:35:56.358822 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533"
[0m23:35:56.360538 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533
[0m23:35:56.363359 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533"
[0m23:35:56.365486 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533"
[0m23:35:56.365998 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533: BEGIN
[0m23:35:56.367325 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.390872 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m23:35:56.392013 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533"
[0m23:35:56.392013 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    payment_id as unique_field,
    count(*) as n_records

from "datamart"."raw"."payments"
where payment_id is not null
group by payment_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m23:35:56.394260 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.payments" does not exist
LINE 18: from "datamart"."raw"."payments"
              ^

[0m23:35:56.394805 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533: ROLLBACK
[0m23:35:56.396460 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533: Close
[0m23:35:56.400311 [debug] [Thread-1 (]: Database Error in test source_unique_raw_payments_payment_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 18: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_payments_payment_id.sql
[0m23:35:56.401548 [error] [Thread-1 (]: 16 of 19 ERROR source_unique_raw_payments_payment_id ........................... [[31mERROR[0m in 0.05s]
[0m23:35:56.402696 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533
[0m23:35:56.403293 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_unique_raw_products_product_id.518dac90ba
[0m23:35:56.403969 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533' to be skipped because of status 'error'.  Reason: Database Error in test source_unique_raw_payments_payment_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 18: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_payments_payment_id.sql.
[0m23:35:56.404561 [info ] [Thread-1 (]: 17 of 19 START test source_unique_raw_products_product_id ...................... [RUN]
[0m23:35:56.405709 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_unique_raw_payments_payment_id.ad2e113533, now test.data_pipeline.source_unique_raw_products_product_id.518dac90ba)
[0m23:35:56.406262 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_unique_raw_products_product_id.518dac90ba
[0m23:35:56.411173 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_unique_raw_products_product_id.518dac90ba"
[0m23:35:56.412309 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_unique_raw_products_product_id.518dac90ba
[0m23:35:56.416150 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_unique_raw_products_product_id.518dac90ba"
[0m23:35:56.418448 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_unique_raw_products_product_id.518dac90ba"
[0m23:35:56.419032 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_products_product_id.518dac90ba: BEGIN
[0m23:35:56.419596 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.461925 [debug] [Thread-1 (]: SQL status: BEGIN in 0.042 seconds
[0m23:35:56.463620 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_unique_raw_products_product_id.518dac90ba"
[0m23:35:56.465421 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_products_product_id.518dac90ba: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_unique_raw_products_product_id.518dac90ba"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    product_id as unique_field,
    count(*) as n_records

from "datamart"."raw"."products"
where product_id is not null
group by product_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m23:35:56.468255 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.products" does not exist
LINE 18: from "datamart"."raw"."products"
              ^

[0m23:35:56.469636 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_products_product_id.518dac90ba: ROLLBACK
[0m23:35:56.474074 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_products_product_id.518dac90ba: Close
[0m23:35:56.481308 [debug] [Thread-1 (]: Database Error in test source_unique_raw_products_product_id (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 18: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_products_product_id.sql
[0m23:35:56.482451 [error] [Thread-1 (]: 17 of 19 ERROR source_unique_raw_products_product_id ........................... [[31mERROR[0m in 0.08s]
[0m23:35:56.484172 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_unique_raw_products_product_id.518dac90ba
[0m23:35:56.485881 [debug] [Thread-1 (]: Began running node test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd
[0m23:35:56.486509 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_unique_raw_products_product_id.518dac90ba' to be skipped because of status 'error'.  Reason: Database Error in test source_unique_raw_products_product_id (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 18: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_products_product_id.sql.
[0m23:35:56.487219 [info ] [Thread-1 (]: 18 of 19 START test source_unique_raw_raw_data_order_id ........................ [RUN]
[0m23:35:56.488361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_pipeline.source_unique_raw_products_product_id.518dac90ba, now test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd)
[0m23:35:56.488942 [debug] [Thread-1 (]: Began compiling node test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd
[0m23:35:56.500333 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd"
[0m23:35:56.502184 [debug] [Thread-1 (]: Began executing node test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd
[0m23:35:56.592852 [debug] [Thread-1 (]: Writing runtime sql for node "test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd"
[0m23:35:56.595118 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd"
[0m23:35:56.596220 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd: BEGIN
[0m23:35:56.597236 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:56.621502 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m23:35:56.622044 [debug] [Thread-1 (]: Using postgres connection "test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd"
[0m23:35:56.623143 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd: /* {"app": "dbt", "dbt_version": "1.9.6", "profile_name": "data_pipeline", "target_name": "dev", "node_id": "test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "datamart"."raw"."raw_data"
where order_id is not null
group by order_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m23:35:56.626415 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.raw_data" does not exist
LINE 18: from "datamart"."raw"."raw_data"
              ^

[0m23:35:56.627432 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd: ROLLBACK
[0m23:35:56.630363 [debug] [Thread-1 (]: On test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd: Close
[0m23:35:56.635602 [debug] [Thread-1 (]: Database Error in test source_unique_raw_raw_data_order_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 18: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_raw_data_order_id.sql
[0m23:35:56.636147 [error] [Thread-1 (]: 18 of 19 ERROR source_unique_raw_raw_data_order_id ............................. [[31mERROR[0m in 0.15s]
[0m23:35:56.637248 [debug] [Thread-1 (]: Finished running node test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd
[0m23:35:56.637809 [debug] [Thread-4 (]: Marking all children of 'test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd' to be skipped because of status 'error'.  Reason: Database Error in test source_unique_raw_raw_data_order_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 18: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_raw_data_order_id.sql.
[0m23:35:56.638914 [debug] [Thread-1 (]: Began running node model.data_pipeline.raw_to_normalized
[0m23:35:56.639477 [info ] [Thread-1 (]: 19 of 19 SKIP relation public.raw_to_normalized ................................ [[33mSKIP[0m]
[0m23:35:56.640040 [debug] [Thread-1 (]: Finished running node model.data_pipeline.raw_to_normalized
[0m23:35:56.640760 [debug] [Thread-4 (]: Marking all children of 'model.data_pipeline.raw_to_normalized' to be skipped because of status 'skipped'. 
[0m23:35:56.642822 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:56.643396 [debug] [MainThread]: On master: BEGIN
[0m23:35:56.643971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:35:56.674872 [debug] [MainThread]: SQL status: BEGIN in 0.031 seconds
[0m23:35:56.676019 [debug] [MainThread]: On master: COMMIT
[0m23:35:56.676680 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:56.676680 [debug] [MainThread]: On master: COMMIT
[0m23:35:56.681764 [debug] [MainThread]: SQL status: COMMIT in 0.004 seconds
[0m23:35:56.682917 [debug] [MainThread]: On master: Close
[0m23:35:56.684036 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:35:56.685173 [debug] [MainThread]: Connection 'list_datamart' was properly closed.
[0m23:35:56.685743 [debug] [MainThread]: Connection 'list_datamart_public' was properly closed.
[0m23:35:56.687346 [debug] [MainThread]: Connection 'test.data_pipeline.source_unique_raw_raw_data_order_id.667867dacd' was properly closed.
[0m23:35:56.688415 [info ] [MainThread]: 
[0m23:35:56.690207 [info ] [MainThread]: Finished running 18 data tests, 1 view model in 0 hours 0 minutes and 2.02 seconds (2.02s).
[0m23:35:56.695588 [debug] [MainThread]: Command end result
[0m23:35:56.722416 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Project\DataPipeline\dags\dbt_project\target\manifest.json
[0m23:35:56.726405 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Project\DataPipeline\dags\dbt_project\target\semantic_manifest.json
[0m23:35:56.737311 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Project\DataPipeline\dags\dbt_project\target\run_results.json
[0m23:35:56.738445 [info ] [MainThread]: 
[0m23:35:56.739442 [info ] [MainThread]: [31mCompleted with 18 errors, 0 partial successes, and 0 warnings:[0m
[0m23:35:56.740443 [info ] [MainThread]: 
[0m23:35:56.741793 [error] [MainThread]:   Database Error in test source_accepted_values_raw_payments_payment_method__Credit_Card__PayPal__Bank_Transfer (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 20:     from "datamart"."raw"."payments"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_pay_81e9ba7a9392ec12ec328aa660bf3829.sql
[0m23:35:56.742785 [info ] [MainThread]: 
[0m23:35:56.742785 [error] [MainThread]:   Database Error in test source_accepted_values_raw_payments_payment_status__Completed__Failed__Pending (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 20:     from "datamart"."raw"."payments"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_pay_9e076b3898151400e6c50cdfdb2e3b16.sql
[0m23:35:56.743791 [info ] [MainThread]: 
[0m23:35:56.745406 [error] [MainThread]:   Database Error in test source_accepted_values_raw_raw_data_payment_status__Paid__Pending__Refunded (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 20:     from "datamart"."raw"."raw_data"
                    ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_accepted_values_raw_raw_76585dff0454bdaee97924d29f62e64d.sql
[0m23:35:56.746428 [info ] [MainThread]: 
[0m23:35:56.747427 [error] [MainThread]:   Database Error in test source_not_null_raw_payments_order_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 17: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_payments_order_id.sql
[0m23:35:56.747943 [info ] [MainThread]: 
[0m23:35:56.748755 [error] [MainThread]:   Database Error in test source_not_null_raw_payments_payment_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 17: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_payments_payment_id.sql
[0m23:35:56.749779 [info ] [MainThread]: 
[0m23:35:56.749779 [error] [MainThread]:   Database Error in test source_not_null_raw_products_category (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_category.sql
[0m23:35:56.751291 [info ] [MainThread]: 
[0m23:35:56.752308 [error] [MainThread]:   Database Error in test source_not_null_raw_products_price (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_price.sql
[0m23:35:56.752308 [info ] [MainThread]: 
[0m23:35:56.753306 [error] [MainThread]:   Database Error in test source_not_null_raw_products_product_id (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_product_id.sql
[0m23:35:56.754306 [info ] [MainThread]: 
[0m23:35:56.754306 [error] [MainThread]:   Database Error in test source_not_null_raw_products_product_name (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 17: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_products_product_name.sql
[0m23:35:56.756077 [info ] [MainThread]: 
[0m23:35:56.757715 [error] [MainThread]:   Database Error in test source_not_null_raw_raw_data_customer_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_customer_id.sql
[0m23:35:56.758745 [info ] [MainThread]: 
[0m23:35:56.759738 [error] [MainThread]:   Database Error in test source_not_null_raw_raw_data_order_date (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_order_date.sql
[0m23:35:56.759738 [info ] [MainThread]: 
[0m23:35:56.761256 [error] [MainThread]:   Database Error in test source_not_null_raw_raw_data_order_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_order_id.sql
[0m23:35:56.762767 [info ] [MainThread]: 
[0m23:35:56.764156 [error] [MainThread]:   Database Error in test source_not_null_raw_raw_data_total_amount (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 17: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_not_null_raw_raw_data_total_amount.sql
[0m23:35:56.765731 [info ] [MainThread]: 
[0m23:35:56.767257 [error] [MainThread]:   Compilation Error in test source_positive_values_raw_products_price (../../models\sources.yml)
  'test_positive_values' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m23:35:56.768279 [info ] [MainThread]: 
[0m23:35:56.769333 [error] [MainThread]:   Compilation Error in test source_positive_values_raw_raw_data_total_amount (../../models\sources.yml)
  'test_positive_values' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m23:35:56.770352 [info ] [MainThread]: 
[0m23:35:56.771355 [error] [MainThread]:   Database Error in test source_unique_raw_payments_payment_id (../../models\sources.yml)
  relation "raw.payments" does not exist
  LINE 18: from "datamart"."raw"."payments"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_payments_payment_id.sql
[0m23:35:56.773351 [info ] [MainThread]: 
[0m23:35:56.775353 [error] [MainThread]:   Database Error in test source_unique_raw_products_product_id (../../models\sources.yml)
  relation "raw.products" does not exist
  LINE 18: from "datamart"."raw"."products"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_products_product_id.sql
[0m23:35:56.776660 [info ] [MainThread]: 
[0m23:35:56.778764 [error] [MainThread]:   Database Error in test source_unique_raw_raw_data_order_id (../../models\sources.yml)
  relation "raw.raw_data" does not exist
  LINE 18: from "datamart"."raw"."raw_data"
                ^
  compiled code at target\run\data_pipeline\../../models\sources.yml\source_unique_raw_raw_data_order_id.sql
[0m23:35:56.779778 [info ] [MainThread]: 
[0m23:35:56.781334 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=18 SKIP=1 TOTAL=19
[0m23:35:56.786018 [debug] [MainThread]: Command `dbt build` failed at 23:35:56.785503 after 4.79 seconds
[0m23:35:56.787962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFAE519D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFAD810A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DFA2D7410>]}
[0m23:35:56.789151 [debug] [MainThread]: Flushing usage events
[0m23:35:57.238268 [debug] [MainThread]: An error was encountered while trying to flush usage events
